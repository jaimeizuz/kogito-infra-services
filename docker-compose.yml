services:
  kogito-bpmn-app-secured:
    container_name: kogito-bpmn-app-secured
    image: dev.local/kogito/kogito-bpmn-app-secured:1.0.0-SNAPSHOT
    profiles:
      - kogito-bpmn-apps
    network_mode: host
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 700M
        reservations:
          memory: 384M
    environment:
      QUARKUS_HTTP_PORT: "8081"
      KOGITO_PERSISTENCE_PROTO_MARSHALLER: "false"
      QUARKUS_HTTP_CORS_ORIGINS: /.*/
      GC_CONTAINER_OPTIONS: "-XX:+UseG1GC"
      # The number if IO threads used to perform IO. This will be automatically set to a reasonable value based on the number of CPU cores if it is not provided.
      # If this is set to a higher value than the number of Vert.x event loops then it will be capped at the number of event loops.
      # In general this should be controlled by setting quarkus.vertx.event-loops-pool-size, this setting should only be used if you want to limit the number
      # of HTTP io threads to a smaller number than the total number of IO threads.
      # QUARKUS_HTTP_IO_THREADS: 5
      # The number of event loops. By default, it matches the number of CPUs detected on the system.
      # QUARKUS_VERTX_EVENT_LOOPS_POOL_SIZE: 5
      # The maximum number of threads. If this is not specified then it will be automatically sized to the greatest of 8 * the number of available processors and 200.
      # For example if there are 4 processors the max threads will be 200. If there are 48 processors it will be 384.
      QUARKUS_THREAD_POOL_MAX_THREADS: 300
      # See https://quarkus.io/guides/datasource#jdbc-configuration
      QUARKUS_DATASOURCE_JDBC_URL: 'jdbc:postgresql://localhost:5432/kogito'
      QUARKUS_DATASOURCE_USERNAME: kogito-user
      QUARKUS_DATASOURCE_PASSWORD: kogito-pass
      QUARKUS_DATASOURCE_DB_KIND: postgresql
      QUARKUS_DATASOURCE_JDBC_ENABLE_METRICS: "true"
      QUARKUS_DATASOURCE_JDBC_METRICS_ENABLED: "true"
      # XA transaction objects datasource
      QUARKUS_DATASOURCE__XOS__JDBC_URL: 'jdbc:postgresql://localhost:5432/xa-object-store'
      QUARKUS_DATASOURCE__XOS__USERNAME: kogito-user
      QUARKUS_DATASOURCE__XOS__PASSWORD: kogito-pass
      QUARKUS_DATASOURCE__XOS__DB_KIND: postgresql
      QUARKUS.DATASOURCE__XOS__JDBC_TRANSACTIONS: disabled
      # The initial size of the pool. Usually you will want to set the initial size to match at least the minimal size, 
      # but this is not enforced so to allow for architectures which prefer a lazy initialization of the connections on boot, 
      # while being able to sustain a minimal pool size after boot. DEFAULT: null
      QUARKUS_DATASOURCE_JDBC_INITIAL_SIZE: 20
      # The datasource pool minimum size. DEFAULT: 0
      QUARKUS_DATASOURCE_JDBC_MIN_SIZE: 20
      # The datasource pool maximum size. DEFAULT: 20
      QUARKUS_DATASOURCE_JDBC_MAX_SIZE: 80
      # The interval at which we validate idle connections in the background. Set to 0 to disable background validation. DEFAULT: 2M
      # QUARKUS_DATASOURCE_JDBC_BACKGROUND_VALIDATION_INTERVAL: 2M
      # Perform foreground validation on connections that have been idle for longer than the specified interval. DEFAULT: null
      # QUARKUS_DATASOURCE_JDBC_FOREGROUND_VALIDATION_INTERVAL: 15S
      # The timeout before cancelling the acquisition of a new connection. DEFAULT: 5S
      # QUARKUS_DATASOURCE_JDBC_ACQUISITION_TIMEOUT: 5S
      # The interval at which we check for connection leaks. DEFAULT: disabled
      # QUARKUS_DATASOURCE_JDBC_LEAK_DETECTION_INTERVAL: 10M
      # The interval at which we try to remove idle connections. DEFAULT: 5M
      # QUARKUS_DATASOURCE_JDBC_IDLE_REMOVAL_INTERVAL: 5M
      # The max lifetime of a connection. DEFAULT: disabled
      # QUARKUS_DATASOURCE_JDBC_MAX_LIFETIME: 1M
      # The transaction isolation level. DEFAULT: null
      # QUARKUS_DATASOURCE_JDBC_TRANSACTION_ISOLATION_LEVEL: undefined, none, read-uncommitted, read-committed, repeatable-read, serializable
      QUARKUS_TRANSACTION-MANAGER_ENABLE-RECOVERY: "true"
      QUARKUS_TRANSACTION-MANAGER_OBJECT-STORE_DATASOURCE: "xos"
      QUARKUS_TRANSACTION-MANAGER_OBJECT-STORE_TYPE: "jdbc"
      QUARKUS_TRANSACTION-MANAGER_OBJECT-STORE_CREATE-TABLE: "true"
      KOGITO_SERVICE_URL: 'http://localhost:8081'
      KOGITO_DATA_INDEX_URL: 'http://localhost:8081'
      KOGITO_DATAINDEX_HTTP_URL: 'http://localhost:8081'
      KOGITO_JOBS_SERVICE_URL: 'http://localhost:8081'
      # The current chunk size in minutes the scheduler handles, it is used to keep a limit number of jobs scheduled
      # in the in-memory scheduler.
      #KOGITO_JOBS-SERVICE_SCHEDULERCHUNKINMINUTES: 10
      # The interval the job loading method runs to fetch the persisted jobs from the repository.
      #KOGITO_JOBS-SERVICE_LOADJOBINTERVALINMINUTES: 10
      # The interval based on the current time the job loading method uses to fetch jobs "FROM (now -
      # {@link #loadJobFromCurrentTimeIntervalInMinutes}) TO {@link #schedulerChunkInMinutes}"
      #KOGITO_JOBS-SERVICE_LOADJOBFROMCURRENTTIMEINTERVALINMINUTES: 0
      # Number of retries configured for the periodic jobs loading procedure. Every time the procedure is started this
      # value is considered.
      KOGITO_JOBS-SERVICE_LOADJOBRETRIES: 3
      # Error strategy to apply when the periodic jobs loading procedure has exceeded the jobLoadReties. NONE, FAIL_SERVICE
      #KOGITO_JOBS-SERVICE_LOADJOBERRORSTRATEGY: FAIL_SERVICE
      KOGITO_JOBS-SERVICE_FORCEEXECUTEEXPIREDJOBS: "true"
      KOGITO_JOBS-SERVICE_FORCEEXECUTEEXPIREDJOBSONSERVICESTART: "true"
      QUARKUS_OTEL_LOGS_ENABLED: "true"
      QUARKUS_OTEL_EXPORTER_OTLP_LOGS_ENDPOINT: http://localhost:4317
      QUARKUS_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://localhost:4317
      #QUARKUS_MICROMETER_EXPORT_OTLP_URL: http://opentelemetry-collector:4318
      QUARKUS_DATASOURCE_JDBC_TELEMETRY: "true"
      QUARKUS_DATASOURCE_JDBC_TELEMETRY_ENABLED: "true"
      QUARKUS_DATASOURCE_JDBC_TRACING: "true"
      QUARKUS_DATASOURCE_JDBC_TRACING_ENABLED: "true"
      QUARKUS_LOG_HANDLER_GELF_ENABLED: "true"
      QUARKUS_LOG_HANDLER_GELF_HOST: localhost
      QUARKUS_LOG_HANDLER_GELF_PORT: 12201
      QUARKUS_LOG_HANDLER_GELF_INCLUDE_FULL_MDC: "true"
      KAFKA_BOOTSTRAP_SERVERS: localhost:9092
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSINSTANCES-EVENTS_CONNECTOR: smallrye-kafka
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSINSTANCES-EVENTS_TOPIC: kogito-processinstances-events
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSINSTANCES-EVENTS_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      MP_MESSAGING_OUTGOING_KOGITO-USERTASKINSTANCES-EVENTS_CONNECTOR: smallrye-kafka
      MP_MESSAGING_OUTGOING_KOGITO-USERTASKINSTANCES-EVENTS_TOPIC: kogito-usertaskinstances-events
      MP_MESSAGING_OUTGOING_KOGITO-USERTASKINSTANCES-EVENTS_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSDEFINITIONS-EVENTS_CONNECTOR: smallrye-kafka
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSDEFINITIONS-EVENTS_TOPIC: kogito-processdefinitions-events
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSDEFINITIONS-EVENTS_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      #KOGITO_ADDON_MESSAGING_INCOMING_DEFAULTNAME: kogito-app-example-incoming-stream
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_BOOTSTRAP_SERVERS: redpanda:9093
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_CONNECTOR: smallrye-kafka
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_TOPIC: sendConfirmationForm
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_VALUE_DESERIALIZER: org.apache.kafka.common.serialization.StringDeserializer
      #KOGITO_ADDON_MESSAGING_OUTGOING_DEFAULTNAME: kogito-app-example-outgoing-stream
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_BOOTSTRAP_SERVERS: redpanda:9093
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_CONNECTOR: smallrye-kafka
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_TOPIC: receiveConfirmation
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      KOGITO_EVENTS_GROUPING: "false"
      KIE_FLYWAY_ENABLED: "true"
      KOGITO_PROCESSES_TRANSACTIONENABLED: "true"
      KOGITO_USERTASKS_TRANSACTIONENABLED: "true"
      QUARKUS_REST_CLIENT__DUMMY_REST_SERVICE__URL: http://localhost:19002
      KOGITO_SECURITY_AUTH_ENABLED: "true"
      KOGITO_SECURITY_AUTH_IMPERSONATION_ALLOWED_FOR_ROLES: managers
      QUARKUS_OIDC_DISCOVERY_ENABLED: "true"
      QUARKUS_OIDC_TENANT_ENABLED: "true"
      QUARKUS_OIDC_AUTH_SERVER_URL: http://localhost:8480/realms/kie
      QUARKUS_OIDC_CLIENT_ID: kie-app
      QUARKUS_OIDC_CREDENTIALS_SECRET: secret
      QUARKUS_OIDC_APPLICATION_TYPE: service
      QUARKUS_OIDC_PROXY_EXTERNAL_CLIENT_ID: kie-management-console
      QUARKUS_HTTP_AUTH_PERMISSION__AUTHENTICATED__PATHS: /*
      QUARKUS_HTTP_AUTH_PERMISSION__AUTHENTICATED__POLICY: authenticated
      QUARKUS_HTTP_AUTH_PERMISSION__PUBLIC__PATHS: /q/*,/docs/*
      QUARKUS_HTTP_AUTH_PERMISSION__PUBLIC__POLICY: permit   
    depends_on:
      postgres-kogito-secured:
        condition: service_started
      redpanda:
        condition: service_healthy
      keycloak:
        condition: service_healthy
  kogito-bpmn-app-unsecured:
    container_name: kogito-bpmn-app-unsecured
    image: dev.local/kogito/kogito-bpmn-app-unsecured:1.0.0-SNAPSHOT
    profiles:
      - kogito-bpmn-apps
    #network_mode: host
    ports:
      - 8082:8082
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 700M
        reservations:
          memory: 384M
    environment:
      QUARKUS_HTTP_PORT: "8082"
      KOGITO_PERSISTENCE_PROTO_MARSHALLER: "false"
      QUARKUS_HTTP_CORS_ORIGINS: /.*/
      QUARKUS_THREAD-POOL_MAX-THREADS: 150
      # See https://quarkus.io/guides/datasource#jdbc-configuration
      #QUARKUS_DATASOURCE_JDBC_URL: 'jdbc:postgresql://localhost:5433/kogito?currentSchema=public'
      QUARKUS_DATASOURCE_JDBC_URL: 'jdbc:postgresql://postgres-kogito-unsecured:5432/kogito'
      QUARKUS_DATASOURCE_USERNAME: kogito-user
      QUARKUS_DATASOURCE_PASSWORD: kogito-pass
      QUARKUS_DATASOURCE_DB_KIND: postgresql
      QUARKUS_DATASOURCE_JDBC_ENABLE_METRICS: "true"
      QUARKUS_DATASOURCE_JDBC_METRICS_ENABLED: "true"
      # XA transaction objects datasource
      #QUARKUS_DATASOURCE__XOS__JDBC_URL: 'jdbc:postgresql://localhost:5433/xa-object-store?currentSchema=public'
      QUARKUS_DATASOURCE__XOS__JDBC_URL: 'jdbc:postgresql://postgres-kogito-unsecured:5432/xa-object-store'
      QUARKUS_DATASOURCE__XOS__USERNAME: kogito-user
      QUARKUS_DATASOURCE__XOS__PASSWORD: kogito-pass
      QUARKUS_DATASOURCE__XOS__DB_KIND: postgresql
      QUARKUS.DATASOURCE__XOS__JDBC_TRANSACTIONS: disabled
      # The initial size of the pool. Usually you will want to set the initial size to match at least the minimal size, 
      # but this is not enforced so to allow for architectures which prefer a lazy initialization of the connections on boot, 
      # while being able to sustain a minimal pool size after boot. DEFAULT: null
      QUARKUS_DATASOURCE_JDBC_INITIAL_SIZE: 20
      # The datasource pool minimum size. DEFAULT: 0
      QUARKUS_DATASOURCE_JDBC_MIN_SIZE: 20
      # The datasource pool maximum size. DEFAULT: 20
      QUARKUS_DATASOURCE_JDBC_MAX_SIZE: 80
      # The interval at which we validate idle connections in the background. Set to 0 to disable background validation. DEFAULT: 2M
      # QUARKUS_DATASOURCE_JDBC_BACKGROUND_VALIDATION_INTERVAL: 2M
      # Perform foreground validation on connections that have been idle for longer than the specified interval. DEFAULT: null
      # QUARKUS_DATASOURCE_JDBC_FOREGROUND_VALIDATION_INTERVAL: 15S
      # The timeout before cancelling the acquisition of a new connection. DEFAULT: 5S
      # QUARKUS_DATASOURCE_JDBC_ACQUISITION_TIMEOUT: 5S
      # The interval at which we check for connection leaks. DEFAULT: disabled
      # QUARKUS_DATASOURCE_JDBC_LEAK_DETECTION_INTERVAL: 10M
      # The interval at which we try to remove idle connections. DEFAULT: 5M
      # QUARKUS_DATASOURCE_JDBC_IDLE_REMOVAL_INTERVAL: 5M
      # The max lifetime of a connection. DEFAULT: disabled
      # QUARKUS_DATASOURCE_JDBC_MAX_LIFETIME: 1M
      # The transaction isolation level. DEFAULT: null
      # QUARKUS_DATASOURCE_JDBC_TRANSACTION_ISOLATION_LEVEL: undefined, none, read-uncommitted, read-committed, repeatable-read, serializable
      QUARKUS_TRANSACTION-MANAGER_ENABLE-RECOVERY: "true"
      QUARKUS_TRANSACTION-MANAGER_OBJECT-STORE_DATASOURCE: "xos"
      QUARKUS_TRANSACTION-MANAGER_OBJECT-STORE_TYPE: "jdbc"
      QUARKUS_TRANSACTION-MANAGER_OBJECT-STORE_CREATE-TABLE: "true"
      KOGITO_SERVICE_URL: 'http://localhost:8082'
      KOGITO_DATA_INDEX_URL: 'http://localhost:8082'
      KOGITO_DATAINDEX_HTTP_URL: 'http://localhost:8082'
      KOGITO_JOBS_SERVICE_URL: 'http://localhost:8082'
      # The current chunk size in minutes the scheduler handles, it is used to keep a limit number of jobs scheduled
      # in the in-memory scheduler.
      #KOGITO_JOBS-SERVICE_SCHEDULERCHUNKINMINUTES: 10
      # The interval the job loading method runs to fetch the persisted jobs from the repository.
      #KOGITO_JOBS-SERVICE_LOADJOBINTERVALINMINUTES: 10
      # The interval based on the current time the job loading method uses to fetch jobs "FROM (now -
      # {@link #loadJobFromCurrentTimeIntervalInMinutes}) TO {@link #schedulerChunkInMinutes}"
      #KOGITO_JOBS-SERVICE_LOADJOBFROMCURRENTTIMEINTERVALINMINUTES: 0
      # Number of retries configured for the periodic jobs loading procedure. Every time the procedure is started this
      # value is considered.
      KOGITO_JOBS-SERVICE_LOADJOBRETRIES: 3
      # Error strategy to apply when the periodic jobs loading procedure has exceeded the jobLoadReties. NONE, FAIL_SERVICE
      #KOGITO_JOBS-SERVICE_LOADJOBERRORSTRATEGY: FAIL_SERVICE
      KOGITO_JOBS-SERVICE_FORCEEXECUTEEXPIREDJOBS: "true"
      KOGITO_JOBS-SERVICE_FORCEEXECUTEEXPIREDJOBSONSERVICESTART: "true"
      QUARKUS_OTEL_LOGS_ENABLED: "true"
      #QUARKUS_OTEL_EXPORTER_OTLP_LOGS_ENDPOINT: http://localhost:4317
      #QUARKUS_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://localhost:4317
      QUARKUS_OTEL_EXPORTER_OTLP_LOGS_ENDPOINT: http://opentelemetry-collector:4317
      QUARKUS_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://opentelemetry-collector:4317
      #QUARKUS_MICROMETER_EXPORT_OTLP_URL: http://opentelemetry-collector:4318
      QUARKUS_DATASOURCE_JDBC_TELEMETRY: "true"
      QUARKUS_DATASOURCE_JDBC_TELEMETRY_ENABLED: "true"
      QUARKUS_DATASOURCE_JDBC_TRACING: "true"
      QUARKUS_DATASOURCE_JDBC_TRACING_ENABLED: "true"
      QUARKUS_LOG_HANDLER_GELF_ENABLED: "true"
      #QUARKUS_LOG_HANDLER_GELF_HOST: localhost
      QUARKUS_LOG_HANDLER_GELF_HOST: logstash
      QUARKUS_LOG_HANDLER_GELF_PORT: 12201
      QUARKUS_LOG_HANDLER_GELF_INCLUDE_FULL_MDC: "true"
      #KAFKA_BOOTSTRAP_SERVERS: localhost:9092
      KAFKA_BOOTSTRAP_SERVERS: redpanda:9093
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSINSTANCES-EVENTS_CONNECTOR: smallrye-kafka
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSINSTANCES-EVENTS_TOPIC: kogito-processinstances-events
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSINSTANCES-EVENTS_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      MP_MESSAGING_OUTGOING_KOGITO-USERTASKINSTANCES-EVENTS_CONNECTOR: smallrye-kafka
      MP_MESSAGING_OUTGOING_KOGITO-USERTASKINSTANCES-EVENTS_TOPIC: kogito-usertaskinstances-events
      MP_MESSAGING_OUTGOING_KOGITO-USERTASKINSTANCES-EVENTS_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSDEFINITIONS-EVENTS_CONNECTOR: smallrye-kafka
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSDEFINITIONS-EVENTS_TOPIC: kogito-processdefinitions-events
      MP_MESSAGING_OUTGOING_KOGITO-PROCESSDEFINITIONS-EVENTS_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      #KOGITO_ADDON_MESSAGING_INCOMING_DEFAULTNAME: kogito-app-example-incoming-stream
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_BOOTSTRAP_SERVERS: redpanda:9093
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_CONNECTOR: smallrye-kafka
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_TOPIC: sendConfirmationForm
      #MP_MESSAGING_INCOMING_KOGITO-INCOMING-STREAM_VALUE_DESERIALIZER: org.apache.kafka.common.serialization.StringDeserializer
      #KOGITO_ADDON_MESSAGING_OUTGOING_DEFAULTNAME: kogito-app-example-outgoing-stream
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_BOOTSTRAP_SERVERS: redpanda:9093
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_CONNECTOR: smallrye-kafka
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_TOPIC: receiveConfirmation
      #MP_MESSAGING_OUTGOING_KOGITO-OUTGOING-STREAM_VALUE_SERIALIZER: org.apache.kafka.common.serialization.StringSerializer
      KOGITO_EVENTS_GROUPING: "false"
      KIE_FLYWAY_ENABLED: "true"
      KOGITO_PROCESSES_TRANSACTIONENABLED: "true"
      KOGITO_USERTASKS_TRANSACTIONENABLED: "true"
      #QUARKUS_REST_CLIENT__DUMMY_REST_SERVICE__URL: http://localhost:19002
      QUARKUS_REST_CLIENT__DUMMY_REST_SERVICE__URL: http://wiremock-studio:9002
    depends_on:
      postgres-kogito-unsecured:
        condition: service_started
      redpanda:
        condition: service_healthy
  bamoe-maven-repository:
    container_name: bamoe-maven-repository
    image: quay.io/bamoe/maven-repository:9.2.0-ibm-0004
    profiles:
      - bamoe-maven-repository
      - full
    ports:
      - '8800:8080'
  kogito-management-console:
    container_name: kogito-management-console
    image: apache/incubator-kie-kogito-management-console:main
    #image: quay.io/bamoe/management-console:9.2.0-ibm-0004
    profiles:
      - full
      - kogito-consoles
    ports:
      - '8280:8080'
    #depends_on:
    #  keycloak:
    #    condition: service_healthy
    environment:
      RUNTIME_TOOLS_MANAGEMENT_CONSOLE_OIDC_CLIENT_CLIENT_ID: kie-management-console
  postgres-kogito-secured:
    container_name: postgres-kogito-secured
    image: 'postgres:16.8-alpine3.21'
    profiles:
      - infra
      - example
      - full
      - kogito-database
    ports:
      - '5432:5432'
    volumes:
      - './sql/postgres-kogito-secured:/docker-entrypoint-initdb.d:Z'
      - './sql/postgres-kogito-secured/postgresql.conf:/etc/postgresql.conf'
    command:
      postgres -c config_file=/etc/postgresql.conf
    healthcheck:
      test:
        - CMD
        - pg_isready
        - '-q'
        - '-d'
        - kogito
        - '-U'
        - kogito-user
      timeout: 45s
      interval: 10s
      retries: 50
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
  postgres-kogito-unsecured:
    container_name: postgres-kogito-unsecured
    image: 'postgres:16.8-alpine3.21'
    profiles:
      - infra
      - example
      - full
      - kogito-database
    ports:
      - '5433:5432'
    volumes:
      - './sql/postgres-kogito-unsecured:/docker-entrypoint-initdb.d:Z'
      - './sql/postgres-kogito-unsecured/postgresql.conf:/etc/postgresql.conf'
    command:
      postgres -c config_file=/etc/postgresql.conf
    healthcheck:
      test:
        - CMD
        - pg_isready
        - '-q'
        - '-d'
        - kogito
        - '-U'
        - kogito-user
      timeout: 45s
      interval: 10s
      retries: 50
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
  postgres-supporting-services:
    container_name: postgres-supporting-services
    image: 'postgres:16.8-alpine3.21'
    profiles:
      - infra
      - example
      - full
      - kogito-database
    ports:
      - '5434:5432'
    volumes:
      - './sql/postgres-supporting-services:/docker-entrypoint-initdb.d:Z'
      - './sql/postgres-supporting-services/postgresql.conf:/etc/postgresql.conf'
    command:
      postgres -c config_file=/etc/postgresql.conf
    healthcheck:
      test:
        - CMD
        - pg_isready
        - '-q'
        - '-d'
        - kogito
        - '-U'
        - kogito-user
      timeout: 45s
      interval: 10s
      retries: 50
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
  postgres-prometheus-exporter:
    # See https://github.com/prometheus-community/postgres_exporter
    container_name: postgres-prometheus-exporter
    image: 'quay.io/prometheuscommunity/postgres-exporter:v0.17.1'
    profiles:
      - full
    ports:
      - 9187:9187
    environment:
      DATA_SOURCE_URI: "postgres-kogito-unsecured:5432?sslmode=disable"
      DATA_SOURCE_USER: postgres
      DATA_SOURCE_PASS: postgres
  pgadmin:
    image: dpage/pgadmin4:9.1
    container_name: pgadmin
    profiles:
      - full
      - pgadmin
    ports:
      - 8055:80
    volumes:
      - ./pgadmin/servers.json:/pgadmin4/servers.json
      - ./pgadmin/pgpass:/pgadmin4/pgpass
    entrypoint: >
      /bin/sh -c "
      cp -f /pgadmin4/pgpass /var/lib/pgadmin/;
      chmod 600 /var/lib/pgadmin/pgpass;
      /entrypoint.sh
      "
    environment:
      PGADMIN_DEFAULT_EMAIL: user@kogito.org
      PGADMIN_DEFAULT_PASSWORD: pass
      PGADMIN_CONFIG_SERVER_MODE: "False"
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: "False"
      GUNICORN_ACCESS_LOGFILE: "/dev/null"
  mysql-server:
    container_name: mysql
    image: jizuzquiza/mysql:8.0.16
    profiles:
      - mysql
    environment:
      MYSQL_ROOT_PASSWORD: password@1
    volumes:
      - mysql_data:/var/lib/mysql
    ports:
    - 3307:3306
  keycloak:
    container_name: keycloak
    #image: quay.io/keycloak/keycloak:23.0.7-0
    image: quay.io/keycloak/keycloak:26.2.1
    profiles:
      - full
      - kogito-consoles
    ports:
      - '8480:8080'
    depends_on:
      postgres-supporting-services:
        condition: service_healthy
    volumes:
      - ./keycloak:/opt/keycloak/data/import:z
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "exec 3<>/dev/tcp/127.0.0.1/9000; echo -e 'GET /health/ready HTTP/1.1\r\nHost: localhost:9000\r\nConnection: close\r\n\r\n' >&3;cat <&3 | grep -q '\"status\": \"UP\"' && exit 0 || exit 1",
        ]
      interval: 2s
      timeout: 1s
      retries: 50
    environment:
      KC_HEALTH_ENABLED: "true"
      DB_VENDOR: POSTGRES
      DB_ADDR: postgres-supporting-services
      DB_DATABASE: keycloak
      DB_USER: kogito-user
      DB_SCHEMA: public
      DB_PASSWORD: kogito-pass
      KEYCLOAK_USER: admin
      KEYCLOAK_PASSWORD: admin
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    command:
      start-dev --import-realm --hostname-port=8480 --health-enabled=true
  redpanda:
    container_name: redpanda
    #image: redpandadata/redpanda:v24.2.14
    image: redpandadata/redpanda:v25.1.1
    profiles:
      - full
      - messaging-redpanda
    ports:
      - 18081:18081
      - 18082:18082
      - 14001:8081
      - 14002:8082
      - 9092:9092
      - 28082:28082
      - 29092:2909
      - 9093:9093
      - 9644:9644
    volumes:
      - redpanda_data:/var/lib/redpanda/data
      #- ./redpanda/bootstrap.yml:/etc/redpanda/.bootstrap.yaml
    #environment:
      #DATA_TRANSFORMS_ENABLED: "true"
    command:
    - redpanda
    - start
    - --smp
    - '6'
    - --reserve-memory
    - 0M
    - --overprovisioned
    - --node-id
    - '0'
    - --kafka-addr
    - PLAINTEXT://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
    - --advertise-kafka-addr
    - PLAINTEXT://redpanda:9093,OUTSIDE://localhost:9092
    - --pandaproxy-addr
    - PLAINTEXT://0.0.0.0:28082,OUTSIDE://0.0.0.0:8082
    - --advertise-pandaproxy-addr
    - PLAINTEXT://redpanda:28082,OUTSIDE://localhost:8082
    - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/brokers" ]
      interval: 1s
      timeout: 1s
      retries: 50
  redpanda-connect:
    # See https://docs.redpanda.com/current/console/quickstart/
    container_name: redpanda-connect
    image: redpandadata/connect:4.53.0
    depends_on:
      - redpanda
    profiles:
      - messaging-redpanda-connect
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: redpanda:9093
      CONNECT_REST_ADVERTISED_HOST_NAME: redpanda-connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      #CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://redpanda:8081
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/brokers" ]
      interval: 1s
      timeout: 1s
      retries: 50
  redpanda-console:
    container_name: redpanda-console
    #image: redpandadata/console:v2.8.1
    image: redpandadata/console:v3.0.1
    profiles:
      - full
      - messaging-redpanda
    # mount the local directory that contains your license key to the container.
    # give Redpanda Console read access to the license.
    volumes:
    # Remove ro?
      - ./license:/etc/redpanda:ro
    entrypoint: /bin/sh
    command: -c 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml && echo "$$CONSOLE_ROLEBINDINGS_CONFIG_FILE" > /tmp/role-bindings.yml && /app/console'
    environment:
      #REDPANDA_LICENSE_FILEPATH: /etc/redpanda/redpanda.license
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda:9093"]
        schemaRegistry:
          enabled: true
          urls: ["http://redpanda:8081"]
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://redpanda:9644"]
        kafkaConnect:
          enabled: false
          clusters:
            - name: datagen
              url: http://redpanda-connect:8083
        authorization:
          roleBindings:
            - roleName: admin
              users:
                - loginType: basic
                  name: "admin"
    ports:
      - 9001:8080
    depends_on:
      - redpanda
  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop:4.1.0
    profiles:
      - messaging-redpanda-kafdrop
    depends_on:
      - redpanda
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "redpanda:9093"
      JVM_OPTS: "-Xms32M -Xmx64M"
      SERVER_SERVLET_CONTEXTPATH: "/"
  jaeger:
    container_name: jaeger
    #image: jaegertracing/jaeger:2.1.0
    image: jaegertracing/jaeger:2.5.0
    profiles:
      - full
      - monitoring
    volumes:
      - './jaeger/jaeger-ui.json:/etc/jaeger/jaeger-ui.json'
    #command: '--query.ui-config /etc/jaeger/jaeger-ui.json'
    environment:
      - METRICS_STORAGE_TYPE=prometheus
      - 'PROMETHEUS_SERVER_URL=http://prometheus:9090'
      - >-
        PROMETHEUS_QUERY_SUPPORT_SPANMETRICS_CONNECTOR=${PROMETHEUS_QUERY_SUPPORT_SPANMETRICS_CONNECTOR:-true}
      - 'PROMETHEUS_QUERY_NAMESPACE=${PROMETHEUS_QUERY_NAMESPACE:-}'
      - 'PROMETHEUS_QUERY_DURATION_UNIT=${PROMETHEUS_QUERY_DURATION_UNIT:-}'
      - PROMETHEUS_QUERY_NORMALIZE_CALLS=true
      - PROMETHEUS_QUERY_NORMALIZE_DURATION=true
    ports:
      - 16686:16686
      - 14268:14268
      - 14269:14269
      - 14250:14250
      - 5778:5778
      - 9411:9411
  otel_collector:
    container_name: opentelemetry-collector
    #image: otel/opentelemetry-collector-contrib:0.116.1
    image: otel/opentelemetry-collector-contrib:0.123.0
    profiles:
      - full
      - monitoring
    volumes:
      - >-
        ./opentelemetry/otel-collector-config.yaml:/etc/otelcol/otel-collector-config.yaml:z
    command: '--config=/etc/otelcol/otel-collector-config.yaml'
    ports:
      - '8889:8889'
      - '13133:13133'
      - '4317:4317'
      - '4318:4318'
      - '15680:55680'
    depends_on:
      - jaeger
      - logstash
  prometheus:
    container_name: prometheus
    #image: prom/prometheus:v3.1.0
    image: prom/prometheus:v3.3.0
    profiles:
      - full
      - monitoring
    volumes:
      - './prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:z'
    ports:
      - '19090:9090'
  grafana:
    container_name: grafana
    #image: grafana/grafana:11.4.0
    image: grafana/grafana:11.6.1
    profiles:
      - dashboards
    volumes:
      - './grafana/grafana.ini:/etc/grafana/grafana.ini:z'
      - >-
       ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/datasource.yaml:z
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_DATABASE_TYPE=postgres
      - GF_DATABASE_HOST=postgres-supporting-services:5432
      - GF_DATABASE_NAME=grafana
      - GF_DATABASE_USER=postgres
      - GF_DATABASE_PASSWORD=postgres
    ports:
      - '3000:3000'
    depends_on:
      postgres-supporting-services:
        condition: service_healthy
  init-tempo:
    #image: grafana/tempo:2.7.0
    image: grafana/tempo:2.7.2
    profiles:
      - init
    user: root
    entrypoint:
      - "chown"
      - "10001:10001"
      - "/var/tempo"
    volumes:
      - ./tempo/data:/var/tempo
  tempo:
    container_name: tempo
    #image: grafana/tempo:2.7.0
    image: grafana/tempo:2.7.2
    profiles:
      - full
      - monitoring
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
    # Remove :z?
      - ./tempo/tempo.yaml:/etc/tempo.yaml:z
      - ./tempo/data:/var/tempo:z
    ports:
      - "3200:3200" # tempo
      - "14317:4317" # otlp grpc
  loki:
    container_name: loki
    #image: grafana/loki:3.2.0
    image: grafana/loki:3.5.0
    profiles:
      - full
      - monitoring
    ports:
      - "3100:3100"
    volumes:
      - ./loki/local-config.yaml:/etc/loki/local-config.yaml:z
    command: -config.file=/etc/loki/local-config.yaml
  elasticsearch:
    container_name: elasticsearch
    #image: docker.io/elastic/elasticsearch:8.16.2
    image: docker.io/elastic/elasticsearch:8.17.5
    profiles:
      - full
      - elk
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
      discovery.type: "single-node"
      xpack.security.enabled: "false"
      cluster.routing.allocation.disk.threshold_enabled: "false"
  logstash:
    container_name: logstash
    #image: docker.io/elastic/logstash:8.16.2
    image: docker.io/elastic/logstash:8.17.5
    profiles:
      - full
      - elk
    environment:
      monitoring.elasticsearch.hosts: http://elasticsearch-host:9200
    volumes:
      - ./logstash/pipelines:/usr/share/logstash/pipeline:z
    ports:
      - "12201:12201/udp"
      - "5000:5000"
      - "9600:9600"
    depends_on:
      - elasticsearch
  kibana:
    container_name: kibana
    #image: docker.io/elastic/kibana:8.16.2
    image: docker.io/elastic/kibana:8.17.5
    environment:
      xpack.monitoring.collection.enabled: "true"
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: d121d3beceec14b5c20ee815cd2c9337
      XPACK_REPORTING_ENCRIPTIONKEY: 3739d02dd358ccb3915cbbd89a6f5150
      XPACK_SECURITY_ENCRIPTIONKEY: 5c4eaf77fdde275944bb1a876a9af87a
    profiles:
      - dashboards
      - elk
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
  wiremock-studio:
    container_name: wiremock-studio
    image: jizuzquiza/wiremock-studio:2.32.0-18
    profiles:
      - full
      - mock-server
    volumes:
      - ./wiremock-data-storage:/home/wiremock:z
    ports:
    - 19000-19010:9000-9010
  castlemock:
    container_name: castlemock
    profiles:
      - mock-server
    image: castlemock/castlemock:v1.63
    ports:
      - 19020:8080
volumes:
    mysql_data: {}
    redpanda_data: {}
